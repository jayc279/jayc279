### Hi there, I'm Jay Yanamandala ðŸ‘‹   
ðŸ“«jyanamandala@gmail.com

**I'm a Generative AI Architect and AI Engineer with excellent understanding and practical experience in building, training, pre-training, fine-tuning, and prompt-engineering techniques. Excellent project management skills, working with and managing cross-functional teams.**

**Hobby** I love working on GenAI LLM works & projects - especially pre-training, fine-tuning, and promtp-engineering - with foundation and Huggingface transformer models/datasets, and in Kaggle competitions

### Certifications	
- :memo: GenAI-LLM (DeepLearning.ai, AWS)        [certificate](https://coursera.org/share/bc98caf7558fc3642a065571f4e6fe48)  
- :memo: Deep Learning Neural Networks 	        [certificate](https://coursera.org/share/06fef9a3ab5b86aad857df668eca4a65)  
- :memo: Machine Learning (Stanford Univ) 	        [certificate](https://coursera.org/share/43f2f8c29abdc5b3d131cbf2f63c95e6)  
- :memo: Machine Leaning (Univ of Washington)	[certificate](https://coursera.org/share/5aafe816eee9f3010669c19c6fe2c685)  
- :memo: Data Sciences (Johns Hopkins Univ) 	    [certificate](https://coursera.org/share/289254eb86f7316234a3c180c7232f95)  

### GenAI Projects
- :newspaper: Trained from scratch Huggingface ROBERTaMLM on Esperanto text file [code](https://github.com/jayc279/GenAI_LLM/blob/main/train_from_scratch/train_from_scratch_smallBERTa_12_6.ipynb)
- :newspaper: Multimodal LLM - (VLP) Visual Language Pretrained Salesforce blip model (Vision Model) against tomytjandra/h-and-m-fashion-caption using Zero-Shot [code](https://github.com/jayc279/GenAI_LLM/blob/main/pre_trained_fine_tuned/image_captioning_h_and_m_fashion_blip.ipynb)
- :newspaper: Pretrained and Finetuned Google Flan-T5-small (Sequence-to-Sequence) model against samsum dataset using PEFT LoRA, an Prompt instructions [code](https://github.com/jayc279/GenAI_LLM/blob/main/pre_trained_fine_tuned/LoRA_pretrain_google_flan_t5_small_samsum.ipynb)
- :newspaper: Streamlit App using Langchain and ChatGPT (OpenAI) model [zilliar_chat](https://github.com/jayc279/GenAI_LLM/tree/main/genai_apps/zilliar_chat)
- :newspaper: Coding, finetuning and evaluating OpenAI GPT transformer generative-AI pipeline model to implement Prompt Engineering techniques to verify and improve quality of completions 

### Deep Learning Projects
- :newspaper: Comprehensive analysis on the explainability of Deep Learning Neural Networks (DLNN) limitations in multiclass classification datasets [code](https://github.com/jayc279/kaggle_notebooks/blob/main/DLNN_OneHot_DecisionTree_PCA_HyperTuning_Flow.ipynb)
- :newspaper: Designed and executed a 34-layer Residual Deep Neural Network for 3D multi-resolution imaging datasets, predicting human vasculature effects in SenNet + HOA project. [code](https://github.com/jayc279/jayc279.github.io/blob/main/work/dl-nn-sennet-hoa-resnet-34.ipynb)
- :newspaper: Applied fully connected Neural Nets to forecast cardiovascular disease risk in individuals with high obesity, optimizing models based on various factors related to family history, height, weight, age, gender, habits. [code](https://github.com/jayc279/jayc279.github.io/blob/main/work/keras-tuner-hyperparameters-search-obesiry-risk.ipynb)
- :newspaper: Developed a fully connected Deep Neural Network to predict customer churn in a banking dataset, enabling proactive customer retention strategies. [code](https://github.com/jayc279/jayc279.github.io/blob/main/work/deep-learning-nn-parameter-search-bankchurn.ipynb)
- :newspaper: Neural Networks Deep Learning Hyperparameters search [blog](https://www.kaggle.com/code/jayyanamandala/neural-networks-deep-learning-hyperparameters-sear)
- :newspaper: Keras-Tuner-hyperparameters-search-for-Obesity-Risk-Prediction [blog](https://www.kaggle.com/code/jayyanamandala/keras-tuner-hyperparameters-search-obesiry-risk)

### SKILLS 
- Experience working with Gen AI Large Language Models (LLM) models: HuggingFaces Transformers, OpenAI, and using Pretraining, finetuning, Prompt Engineering with different kinds of feedback (RLHF, RLAIF), RAG methodologies to improve accuracy unseen/test read world data.
- Multimodal LLM, LangChain Expression language (LCEL), LlamaIndex,
- Experience working with TensorFlow, Keras, PyTorch, NLP, Transformers, Data Visualization techniques, Image Augmentation, Reinforcement Learning, Statistical Analysis.
- Proficient in problem-solving, QA methodologies, and testing frameworks.
- Programming languages including Python, R, Perl, PHP, Tcl, Shell, with experience in C++ and C.
- Cloud platforms: Google Colab, Google Cloud, AWS Sagemaker, AWS EC2.

### Languages and Tools
- Python							PyTorch							TensorFlow					Keras		 SciKit-Learn
- Langchain						LlamaIndex
- Google Cloud				AWS									GitCode

<!--
### Hi there ðŸ‘‹

**jayc279/jayc279** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
